
---
title: "Segmentation"
params:
   images_path: "/assets/images/segmentation/"
---

## Overview

- Introduction & Motivation
- Semantic Segmentation
- Instance Segmentation
- Panoptic Segmentation
- Metrics

# Introduction & Motivation

## Image Segmentation

![Source: @johnson_eecs_2019]({{< meta params.images_path >}}overview.jpg){width=100% height=70%}

## Semantic Segmentation: Road Segmentation

![Top: Photo, Bottom: Annotated Segmentation Map. Source: @cordts_cityscapes_2016]({{< meta params.images_path >}}road_segmentation_example.png){width=100% height=70%}

## Semantic Segmentation: Medical

![Source: @novikov_fully_2018]({{< meta params.images_path >}}chest_segmentation.jpg){width=100% height=70%}

## Instance Segmentation

![Instance Segmentation. Source: @he_mask_2018]({{< meta params.images_path >}}instance_segmentation_example.jpg){width=100% height=70%}

# Semantic Segmentation

## Sliding Window

![Source: @johnson_eecs_2019]({{< meta params.images_path >}}sliding_window.jpg){width=100% height=70%}

## Fully-Convolutional Network - Concept

![Source: @johnson_eecs_2019]({{< meta params.images_path >}}fully_conv_slide.jpg){width=100% height=70%}

## Fully-Convolutional Network

![Source: @tai_pca-aided_2017. Architecture is applied as in the FCN paper by @shelhamer_fully_2016]({{< meta params.images_path >}}fcn_architecture.png){width=100% height=70%}

## Fully-Convolutional Network: Results

![From left to right shows the results of models with skip connections to increasingly earlier layers. Far right is the ground truth. Source: @shelhamer_fully_2016]({{< meta params.images_path >}}improvements_with_skip_connections.jpg){width=100% height=70%}

## Encoder-Decoder: Concept

![Source: @johnson_eecs_2019]({{< meta params.images_path >}}fully_conv_deconv.jpg){width=100% height=70%}

## Encoder-Decoder

![Source: @noh_learning_2015]({{< meta params.images_path >}}fcn_deconv.jpg){width=100% height=70%}

## Upsampling: Unpooling

![Source: @johnson_eecs_2019]({{< meta params.images_path >}}unpooling.jpg){width=100% height=70%}

## Upsampling: Unpooling with Switch

![Source: @noh_learning_2015]({{< meta params.images_path >}}unpooling_switch.jpg){width=100% height=70%}

## Upsampling: Unpooling with Switch

![Source: @johnson_eecs_2019]({{< meta params.images_path >}}max_unpooling.jpg){width=100% height=70%}

## Upsampling: Interpolation

![Source: @johnson_eecs_2019]({{< meta params.images_path >}}bilinear_interpolation.jpg){width=100% height=70%}

## Transposed Convolution

![Transposed Convolution with kernel size 2 and stride 2.]({{< meta params.images_path >}}transposed_conv_example.png){width=100% height=70%}

## Transposed Convolution

![Source: @johnson_eecs_2019]({{< meta params.images_path >}}transposed_conv.jpg){width=100% height=70%}

## Transposed Convolution: Matrix Notation

![Source: @johnson_eecs_2019. $x$ is the kernel, $X$ is the kernel as a matrix, $a$ is the input.]({{< meta params.images_path >}}transposed_conv_as_matrix_mult.jpg){width=100% height=70%}

## UNet: Semantic Segmentation

![Source: @ronneberger_u-net_2015]({{< meta params.images_path >}}unet_example2.jpg){width=100% height=70%}

## UNet: Architecture

![Source: @ronneberger_u-net_2015]({{< meta params.images_path >}}unet.jpg){width=100% height=70%}

## Loss

![Pixel-Level Softmax illustrated for a single pixel. Output is $H \times W \times K$.]({{< meta params.images_path >}}pixel_level_softmax.jpg){width=100% height=70%}

## Cross-Entropy Loss Function

$$
CE = - \sum_{i=1}^N \sum_{j=1}^K y_j^{(i)} \log \hat{y}_j^{(i)}
$$

- $N$: Number of pixels
- $K$: Number of classes
- $\hat{y}_j, y_j$: Prediction / Ground truth for class $j$

# Instance Segmentation

## Mask R-CNN

![Source: @he_mask_2018]({{< meta params.images_path >}}mask_rcnn.jpg){width=100% height=70%}

## Loss Function

$$
\text{binary CE} = - \sum_{i=1}^{N^2}  \Big( (\log \hat{y}_k^{(i)})^{y_k^{(i)}} + (\log (1-\hat{y}_k^{(i)}))^{(1 - y_k^{(i)})} \Big) 
$$

## Mask R-CNN: Masks

![Source: @he_mask_2018]({{< meta params.images_path >}}mask_rcnn_output.jpg){width=100% height=70%}

## Mask R-CNN: Mask Ground Truth

![Source: @johnson_eecs_2019]({{< meta params.images_path >}}mask_rcnn_targets.jpg){width=100% height=70%}

## Mask R-CNN: Results

![Source: @he_mask_2018]({{< meta params.images_path >}}mask_rcnn_results.jpg){width=100% height=70%}

# Panoptic Segmentation

## Panoptic Segmentation

![Source: @johnson_eecs_2019]({{< meta params.images_path >}}things_and_stuff.jpg){width=100% height=70%}

## Panoptic Segmentation

![Source: @johnson_eecs_2019]({{< meta params.images_path >}}panoptic_segmentation.jpg){width=100% height=70%}

# Metrics

## Pixel Accuracy

$$
\text{PA} = \frac{\sum_{i=0}^Kp_{ii}}{\sum_{i=0}^K\sum_{j=0}^K p_{ij}}
$$

## Mean Pixel Accuracy

$$
\text{MPA} = \frac{1}{K+1} \sum_{i=0}^K \frac{p_{ii}}{\sum_{j=0}^K p_{ij}}
$$

Mean accuracy over all classes (equally weighted).

## Intersection over Union (IoU)

$$
\text{IoU} = \frac{\lvert A \cap B \rvert}{\lvert A \cup B \rvert}
$$

Same metric as in object detection, except that the regions are not rectangular.

## Precision / Recall / F1

$$
\text{Precision} = \frac{TP}{TP + FP}
$$

$$
\text{Recall} = \frac{TP}{TP + FN}
$$

F-1 is the harmonic mean of precision and recall: 

$$
\text{F1} = \frac{2 \text{Precision Recall}}{\text{Precision} + \text{Recall}}
$$

## Dice Coefficient

$$
\text{Dice} = \frac{2 \lvert A \cap B \rvert}{\lvert A \rvert + \lvert  B \rvert}
$$

Very similar to IoU. Usage is domain-specific, e.g., medical.

# References

::: {#refs}
:::
